{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FineTune_Marian_From_Ukranian2English_to_Serbian2English.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets transformers sentencepiece sacrebleu==1.5.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8Qe5Cd4D7_0",
        "outputId": "b9676e53-243a-4c56-fbfa-430796008113"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (1.18.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.15.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n",
            "Collecting sacrebleu==1.5.1\n",
            "  Downloading sacrebleu-1.5.1-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 1.8 MB/s \n",
            "\u001b[?25hCollecting portalocker==2.0.0\n",
            "  Downloading portalocker-2.0.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.1.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.10.1)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.62.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.4.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.10)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.7.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Installing collected packages: portalocker, sacrebleu\n",
            "  Attempting uninstall: portalocker\n",
            "    Found existing installation: portalocker 2.3.2\n",
            "    Uninstalling portalocker-2.3.2:\n",
            "      Successfully uninstalled portalocker-2.3.2\n",
            "  Attempting uninstall: sacrebleu\n",
            "    Found existing installation: sacrebleu 2.0.0\n",
            "    Uninstalling sacrebleu-2.0.0:\n",
            "      Successfully uninstalled sacrebleu-2.0.0\n",
            "Successfully installed portalocker-2.0.0 sacrebleu-1.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4qUIBNCFDTJL"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset, load_metric"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "en_sr_train = load_dataset(\"setimes\", \"en-sr\", split='train[0:10000]')\n",
        "en_sr_val = load_dataset(\"setimes\", \"en-sr\", split='train[10000:12500]')\n",
        "en_sr_test = load_dataset(\"setimes\", \"en-sr\", split='train[12500:15000]')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxBgaocPDifN",
        "outputId": "499be9fe-d46d-4738-8135-6d8fcd4afdcb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reusing dataset setimes (/root/.cache/huggingface/datasets/setimes/en-sr/1.0.0/5b0222bb707caa9d423c61813ef94861e1ccdf82fa4b0bdf4a98de3c9fd33d0d)\n",
            "Reusing dataset setimes (/root/.cache/huggingface/datasets/setimes/en-sr/1.0.0/5b0222bb707caa9d423c61813ef94861e1ccdf82fa4b0bdf4a98de3c9fd33d0d)\n",
            "Reusing dataset setimes (/root/.cache/huggingface/datasets/setimes/en-sr/1.0.0/5b0222bb707caa9d423c61813ef94861e1ccdf82fa4b0bdf4a98de3c9fd33d0d)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "en_sr_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iM4MS9PUJIh3",
        "outputId": "0eeebf1c-6f93-41a4-a208-1979e7d0448a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['id', 'translation'],\n",
              "    num_rows: 10000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "en_sr_val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxeOYXyBKaEc",
        "outputId": "299b5249-0c2f-402b-bd96-e464979d60b7"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['id', 'translation'],\n",
              "    num_rows: 2500\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "en_sr_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xo94TlwHKaB5",
        "outputId": "40fe7161-af4d-474b-df1a-af6fb6f6ef86"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['id', 'translation'],\n",
              "    num_rows: 2500\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "en_sr_train[\"translation\"][:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9yhs6ppGmpp",
        "outputId": "d7be1717-33cb-4ef8-c202-b23c429161d8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'en': \"Kosovo's privatisation process is under scrutiny\",\n",
              "  'sr': 'Proces privatizacije na Kosovu pod lupom'},\n",
              " {'en': 'Kosovo is taking a hard look at its privatisation process in light of recurring complaints.',\n",
              "  'sr': 'Kosovo ozbiljno analizira svoje procese privatizacije u svetlu čestih pritužbi.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-uk-en\")"
      ],
      "metadata": {
        "id": "hhW8c0l-DiV4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prefix = \"\"\n",
        "max_input_length = 128\n",
        "max_target_length = 128\n",
        "source_lang = \"sr\"\n",
        "target_lang = \"en\"\n",
        "\n",
        "def preprocess_function(sentences):\n",
        "    inputs = [prefix + sentence[source_lang] for sentence in sentences[\"translation\"]]\n",
        "    targets = [sentence[target_lang] for sentence in sentences[\"translation\"]]\n",
        "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
        "    # Setup the tokenizer for targets\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs"
      ],
      "metadata": {
        "id": "rzb5JuZKGCah"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess_function(en_sr_train[:2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOmc9XnfDiTw",
        "outputId": "39ee1a0d-80f4-446f-af7b-e764d2998208"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [[7447, 2699, 11, 1984, 2061, 1528, 13865, 7597, 3395, 4037, 341, 42, 2962, 6187, 4928, 1528, 1211, 8524, 174, 4173, 2474, 5087, 0], [6187, 4928, 6432, 2596, 1372, 371, 2189, 4037, 2182, 96, 612, 8592, 395, 2058, 701, 6432, 4037, 341, 6596, 2699, 3119, 1984, 2061, 1528, 13865, 7597, 3395, 4037, 341, 10617, 701, 281, 38, 6531, 42, 50665, 2762, 395, 1374, 1984, 21261, 1211, 60730, 371, 395, 3, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[56759, 7, 11, 36994, 6417, 38, 39035, 2354, 23, 529, 42359, 0], [56759, 23, 1180, 13, 875, 434, 84, 324, 36994, 6417, 38, 39035, 2354, 14, 1025, 8, 41418, 29918, 3, 0]]}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_train = en_sr_train.map(preprocess_function, batched=True)\n",
        "tokenized_val = en_sr_val.map(preprocess_function, batched=True)\n",
        "tokenized_test = en_sr_test.map(preprocess_function, batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsdWNYIpDiRd",
        "outputId": "9ee058d8-051b-40ff-efa6-72bb841cd611"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/setimes/en-sr/1.0.0/5b0222bb707caa9d423c61813ef94861e1ccdf82fa4b0bdf4a98de3c9fd33d0d/cache-082ae2b030b7f85d.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/setimes/en-sr/1.0.0/5b0222bb707caa9d423c61813ef94861e1ccdf82fa4b0bdf4a98de3c9fd33d0d/cache-0d043166226cb442.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/setimes/en-sr/1.0.0/5b0222bb707caa9d423c61813ef94861e1ccdf82fa4b0bdf4a98de3c9fd33d0d/cache-bee70e3a3f0c098a.arrow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-uk-en\")"
      ],
      "metadata": {
        "id": "2V2odAUxDiPG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 8\n",
        "model_name = \"opus-mt-uk-en\"\n",
        "\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    f\"{model_name}-finetuned-{source_lang}-to-{target_lang}\",\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=10,\n",
        "    predict_with_generate=True    \n",
        ")\n",
        "\n",
        "metric = load_metric(\"sacrebleu\")\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
      ],
      "metadata": {
        "id": "W9LSyUYjDiMs"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def postprocess_text(preds, labels):\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [[label.strip()] for label in labels]\n",
        "    return preds, labels\n",
        "\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "    # Replace -100 in the labels as we can't decode them.\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    \n",
        "    # Some simple post-processing\n",
        "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
        "\n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "    result = {\n",
        "        \"bleu\": result[\"score\"] \n",
        "    }\n",
        "\n",
        "    prediction_lens = [\n",
        "        np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds\n",
        "    ]\n",
        "\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    result = {\n",
        "        k: round(v, 4) for k, v in result.items()\n",
        "    }\n",
        "    return result"
      ],
      "metadata": {
        "id": "rkYyXoDFDiKo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_val,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "id": "_QmBgEOMDiIA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "W-yq-YCoDiFq",
        "outputId": "e33d2aaf-c5fc-4684-fdb1-77e7f52c273a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the training set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation, id.\n",
            "***** Running training *****\n",
            "  Num examples = 10000\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 12500\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='12500' max='12500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [12500/12500 2:28:13, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Bleu</th>\n",
              "      <th>Gen Len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.261300</td>\n",
              "      <td>2.725676</td>\n",
              "      <td>16.391100</td>\n",
              "      <td>30.887200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.405300</td>\n",
              "      <td>2.365355</td>\n",
              "      <td>22.235200</td>\n",
              "      <td>30.018000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.070800</td>\n",
              "      <td>2.207114</td>\n",
              "      <td>25.296500</td>\n",
              "      <td>29.544400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.754300</td>\n",
              "      <td>2.118623</td>\n",
              "      <td>27.239300</td>\n",
              "      <td>29.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.593800</td>\n",
              "      <td>2.067059</td>\n",
              "      <td>28.479600</td>\n",
              "      <td>29.007200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.455100</td>\n",
              "      <td>2.036848</td>\n",
              "      <td>29.382700</td>\n",
              "      <td>28.874400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.349900</td>\n",
              "      <td>2.023442</td>\n",
              "      <td>29.841600</td>\n",
              "      <td>29.001600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.262100</td>\n",
              "      <td>2.014832</td>\n",
              "      <td>30.160600</td>\n",
              "      <td>28.773200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.237800</td>\n",
              "      <td>2.008014</td>\n",
              "      <td>30.209400</td>\n",
              "      <td>28.787200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.197800</td>\n",
              "      <td>2.006981</td>\n",
              "      <td>30.350000</td>\n",
              "      <td>28.757600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to opus-mt-uk-en-finetuned-sr-to-en/checkpoint-500\n",
            "Configuration saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-500/config.json\n",
            "Model weights saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-500/special_tokens_map.json\n",
            "Saving model checkpoint to opus-mt-uk-en-finetuned-sr-to-en/checkpoint-1000\n",
            "Configuration saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-1000/config.json\n",
            "Model weights saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-1000/pytorch_model.bin\n",
            "tokenizer config file saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-1000/tokenizer_config.json\n",
            "Special tokens file saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-1000/special_tokens_map.json\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2500\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to opus-mt-uk-en-finetuned-sr-to-en/checkpoint-1500\n",
            "Configuration saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-1500/config.json\n",
            "Model weights saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-1500/pytorch_model.bin\n",
            "tokenizer config file saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-1500/tokenizer_config.json\n",
            "Special tokens file saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-1500/special_tokens_map.json\n",
            "Saving model checkpoint to opus-mt-uk-en-finetuned-sr-to-en/checkpoint-2000\n",
            "Configuration saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-2000/config.json\n",
            "Model weights saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-2000/pytorch_model.bin\n",
            "tokenizer config file saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-2000/tokenizer_config.json\n",
            "Special tokens file saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-2000/special_tokens_map.json\n",
            "Deleting older checkpoint [opus-mt-uk-en-finetuned-sr-to-en/checkpoint-500] due to args.save_total_limit\n",
            "Saving model checkpoint to opus-mt-uk-en-finetuned-sr-to-en/checkpoint-2500\n",
            "Configuration saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-2500/config.json\n",
            "Model weights saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-2500/pytorch_model.bin\n",
            "tokenizer config file saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-2500/tokenizer_config.json\n",
            "Special tokens file saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-2500/special_tokens_map.json\n",
            "Deleting older checkpoint [opus-mt-uk-en-finetuned-sr-to-en/checkpoint-1000] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2500\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to opus-mt-uk-en-finetuned-sr-to-en/checkpoint-3000\n",
            "Configuration saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-3000/config.json\n",
            "Model weights saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-3000/pytorch_model.bin\n",
            "tokenizer config file saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-3000/tokenizer_config.json\n",
            "Special tokens file saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-3000/special_tokens_map.json\n",
            "Deleting older checkpoint [opus-mt-uk-en-finetuned-sr-to-en/checkpoint-1500] due to args.save_total_limit\n",
            "Saving model checkpoint to opus-mt-uk-en-finetuned-sr-to-en/checkpoint-3500\n",
            "Configuration saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-3500/config.json\n",
            "Model weights saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-3500/pytorch_model.bin\n",
            "tokenizer config file saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-3500/tokenizer_config.json\n",
            "Special tokens file saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-3500/special_tokens_map.json\n",
            "Deleting older checkpoint [opus-mt-uk-en-finetuned-sr-to-en/checkpoint-2000] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2500\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to opus-mt-uk-en-finetuned-sr-to-en/checkpoint-4000\n",
            "Configuration saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-4000/config.json\n",
            "Model weights saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-4000/pytorch_model.bin\n",
            "tokenizer config file saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-4000/tokenizer_config.json\n",
            "Special tokens file saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-4000/special_tokens_map.json\n",
            "Deleting older checkpoint [opus-mt-uk-en-finetuned-sr-to-en/checkpoint-2500] due to args.save_total_limit\n",
            "Saving model checkpoint to opus-mt-uk-en-finetuned-sr-to-en/checkpoint-4500\n",
            "Configuration saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-4500/config.json\n",
            "Model weights saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-4500/pytorch_model.bin\n",
            "tokenizer config file saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-4500/tokenizer_config.json\n",
            "Special tokens file saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-4500/special_tokens_map.json\n",
            "Deleting older checkpoint [opus-mt-uk-en-finetuned-sr-to-en/checkpoint-3000] due to args.save_total_limit\n",
            "Saving model checkpoint to opus-mt-uk-en-finetuned-sr-to-en/checkpoint-5000\n",
            "Configuration saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-5000/config.json\n",
            "Model weights saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-5000/pytorch_model.bin\n",
            "tokenizer config file saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-5000/tokenizer_config.json\n",
            "Special tokens file saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-5000/special_tokens_map.json\n",
            "Deleting older checkpoint [opus-mt-uk-en-finetuned-sr-to-en/checkpoint-3500] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2500\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to opus-mt-uk-en-finetuned-sr-to-en/checkpoint-5500\n",
            "Configuration saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-5500/config.json\n",
            "Model weights saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-5500/pytorch_model.bin\n",
            "tokenizer config file saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-5500/tokenizer_config.json\n",
            "Special tokens file saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-5500/special_tokens_map.json\n",
            "Deleting older checkpoint [opus-mt-uk-en-finetuned-sr-to-en/checkpoint-4000] due to args.save_total_limit\n",
            "Saving model checkpoint to opus-mt-uk-en-finetuned-sr-to-en/checkpoint-6000\n",
            "Configuration saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-6000/config.json\n",
            "Model weights saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-6000/pytorch_model.bin\n",
            "tokenizer config file saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-6000/tokenizer_config.json\n",
            "Special tokens file saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-6000/special_tokens_map.json\n",
            "Deleting older checkpoint [opus-mt-uk-en-finetuned-sr-to-en/checkpoint-4500] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2500\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to opus-mt-uk-en-finetuned-sr-to-en/checkpoint-6500\n",
            "Configuration saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-6500/config.json\n",
            "Model weights saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-6500/pytorch_model.bin\n",
            "tokenizer config file saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-6500/tokenizer_config.json\n",
            "Special tokens file saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-6500/special_tokens_map.json\n",
            "Deleting older checkpoint [opus-mt-uk-en-finetuned-sr-to-en/checkpoint-5000] due to args.save_total_limit\n",
            "Saving model checkpoint to opus-mt-uk-en-finetuned-sr-to-en/checkpoint-7000\n",
            "Configuration saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-7000/config.json\n",
            "Model weights saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-7000/pytorch_model.bin\n",
            "tokenizer config file saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-7000/tokenizer_config.json\n",
            "Special tokens file saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-7000/special_tokens_map.json\n",
            "Deleting older checkpoint [opus-mt-uk-en-finetuned-sr-to-en/checkpoint-5500] due to args.save_total_limit\n",
            "Saving model checkpoint to opus-mt-uk-en-finetuned-sr-to-en/checkpoint-7500\n",
            "Configuration saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-7500/config.json\n",
            "Model weights saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-7500/pytorch_model.bin\n",
            "tokenizer config file saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-7500/tokenizer_config.json\n",
            "Special tokens file saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-7500/special_tokens_map.json\n",
            "Deleting older checkpoint [opus-mt-uk-en-finetuned-sr-to-en/checkpoint-6000] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2500\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to opus-mt-uk-en-finetuned-sr-to-en/checkpoint-8000\n",
            "Configuration saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-8000/config.json\n",
            "Model weights saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-8000/pytorch_model.bin\n",
            "tokenizer config file saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-8000/tokenizer_config.json\n",
            "Special tokens file saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-8000/special_tokens_map.json\n",
            "Deleting older checkpoint [opus-mt-uk-en-finetuned-sr-to-en/checkpoint-6500] due to args.save_total_limit\n",
            "Saving model checkpoint to opus-mt-uk-en-finetuned-sr-to-en/checkpoint-8500\n",
            "Configuration saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-8500/config.json\n",
            "Model weights saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-8500/pytorch_model.bin\n",
            "tokenizer config file saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-8500/tokenizer_config.json\n",
            "Special tokens file saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-8500/special_tokens_map.json\n",
            "Deleting older checkpoint [opus-mt-uk-en-finetuned-sr-to-en/checkpoint-7000] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2500\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to opus-mt-uk-en-finetuned-sr-to-en/checkpoint-9000\n",
            "Configuration saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-9000/config.json\n",
            "Model weights saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-9000/pytorch_model.bin\n",
            "tokenizer config file saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-9000/tokenizer_config.json\n",
            "Special tokens file saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-9000/special_tokens_map.json\n",
            "Deleting older checkpoint [opus-mt-uk-en-finetuned-sr-to-en/checkpoint-7500] due to args.save_total_limit\n",
            "Saving model checkpoint to opus-mt-uk-en-finetuned-sr-to-en/checkpoint-9500\n",
            "Configuration saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-9500/config.json\n",
            "Model weights saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-9500/pytorch_model.bin\n",
            "tokenizer config file saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-9500/tokenizer_config.json\n",
            "Special tokens file saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-9500/special_tokens_map.json\n",
            "Deleting older checkpoint [opus-mt-uk-en-finetuned-sr-to-en/checkpoint-8000] due to args.save_total_limit\n",
            "Saving model checkpoint to opus-mt-uk-en-finetuned-sr-to-en/checkpoint-10000\n",
            "Configuration saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-10000/config.json\n",
            "Model weights saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-10000/pytorch_model.bin\n",
            "tokenizer config file saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-10000/tokenizer_config.json\n",
            "Special tokens file saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-10000/special_tokens_map.json\n",
            "Deleting older checkpoint [opus-mt-uk-en-finetuned-sr-to-en/checkpoint-8500] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2500\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to opus-mt-uk-en-finetuned-sr-to-en/checkpoint-10500\n",
            "Configuration saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-10500/config.json\n",
            "Model weights saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-10500/pytorch_model.bin\n",
            "tokenizer config file saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-10500/tokenizer_config.json\n",
            "Special tokens file saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-10500/special_tokens_map.json\n",
            "Deleting older checkpoint [opus-mt-uk-en-finetuned-sr-to-en/checkpoint-9000] due to args.save_total_limit\n",
            "Saving model checkpoint to opus-mt-uk-en-finetuned-sr-to-en/checkpoint-11000\n",
            "Configuration saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-11000/config.json\n",
            "Model weights saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-11000/pytorch_model.bin\n",
            "tokenizer config file saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-11000/tokenizer_config.json\n",
            "Special tokens file saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-11000/special_tokens_map.json\n",
            "Deleting older checkpoint [opus-mt-uk-en-finetuned-sr-to-en/checkpoint-9500] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2500\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to opus-mt-uk-en-finetuned-sr-to-en/checkpoint-11500\n",
            "Configuration saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-11500/config.json\n",
            "Model weights saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-11500/pytorch_model.bin\n",
            "tokenizer config file saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-11500/tokenizer_config.json\n",
            "Special tokens file saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-11500/special_tokens_map.json\n",
            "Deleting older checkpoint [opus-mt-uk-en-finetuned-sr-to-en/checkpoint-10000] due to args.save_total_limit\n",
            "Saving model checkpoint to opus-mt-uk-en-finetuned-sr-to-en/checkpoint-12000\n",
            "Configuration saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-12000/config.json\n",
            "Model weights saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-12000/pytorch_model.bin\n",
            "tokenizer config file saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-12000/tokenizer_config.json\n",
            "Special tokens file saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-12000/special_tokens_map.json\n",
            "Deleting older checkpoint [opus-mt-uk-en-finetuned-sr-to-en/checkpoint-10500] due to args.save_total_limit\n",
            "Saving model checkpoint to opus-mt-uk-en-finetuned-sr-to-en/checkpoint-12500\n",
            "Configuration saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-12500/config.json\n",
            "Model weights saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-12500/pytorch_model.bin\n",
            "tokenizer config file saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-12500/tokenizer_config.json\n",
            "Special tokens file saved in opus-mt-uk-en-finetuned-sr-to-en/checkpoint-12500/special_tokens_map.json\n",
            "Deleting older checkpoint [opus-mt-uk-en-finetuned-sr-to-en/checkpoint-11000] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2500\n",
            "  Batch size = 8\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=12500, training_loss=1.7997833544921875, metrics={'train_runtime': 8893.704, 'train_samples_per_second': 11.244, 'train_steps_per_second': 1.405, 'total_flos': 3162658125643776.0, 'train_loss': 1.7997833544921875, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "\n",
        "# src_text = ['Ovaj korak jedna je od mera koje Turska planira da sprovede nakon nedavnog porasta napada koje su izveli teroristi povezani sa zabranjenom Kurdistanskom radničkom partijom.']\n",
        "src_text = ['Turska priprema amandmane na antiteroristički zakon']\n",
        "model_name = 'opus-mt-uk-en-finetuned-sr-to-en/checkpoint-1000'\n",
        "\n",
        "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "model = MarianMTModel.from_pretrained(model_name)\n",
        "translated = model.generate(**tokenizer(src_text, return_tensors=\"pt\", padding=True))\n",
        "[tokenizer.decode(t, skip_special_tokens=True) for t in translated]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNNuejYIDiDS",
        "outputId": "ca89dd99-6b95-4363-8725-48b19f25a938"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Didn't find file opus-mt-uk-en-finetuned-sr-to-en/checkpoint-1000/added_tokens.json. We won't load it.\n",
            "Didn't find file opus-mt-uk-en-finetuned-sr-to-en/checkpoint-1000/tokenizer.json. We won't load it.\n",
            "loading file opus-mt-uk-en-finetuned-sr-to-en/checkpoint-1000/source.spm\n",
            "loading file opus-mt-uk-en-finetuned-sr-to-en/checkpoint-1000/target.spm\n",
            "loading file opus-mt-uk-en-finetuned-sr-to-en/checkpoint-1000/vocab.json\n",
            "loading file opus-mt-uk-en-finetuned-sr-to-en/checkpoint-1000/tokenizer_config.json\n",
            "loading file None\n",
            "loading file opus-mt-uk-en-finetuned-sr-to-en/checkpoint-1000/special_tokens_map.json\n",
            "loading file None\n",
            "loading configuration file opus-mt-uk-en-finetuned-sr-to-en/checkpoint-1000/config.json\n",
            "Model config MarianConfig {\n",
            "  \"_name_or_path\": \"Helsinki-NLP/opus-mt-uk-en\",\n",
            "  \"_num_labels\": 3,\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"swish\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": false,\n",
            "  \"architectures\": [\n",
            "    \"MarianMTModel\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bad_words_ids\": [\n",
            "    [\n",
            "      61586\n",
            "    ]\n",
            "  ],\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_attention_heads\": 8,\n",
            "  \"decoder_ffn_dim\": 2048,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 61586,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 8,\n",
            "  \"encoder_ffn_dim\": 2048,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 6,\n",
            "  \"eos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 0,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"max_length\": 512,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"marian\",\n",
            "  \"normalize_before\": false,\n",
            "  \"normalize_embedding\": false,\n",
            "  \"num_beams\": 6,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 61586,\n",
            "  \"scale_embedding\": true,\n",
            "  \"static_position_embeddings\": true,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.15.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 61587\n",
            "}\n",
            "\n",
            "loading weights file opus-mt-uk-en-finetuned-sr-to-en/checkpoint-1000/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing MarianMTModel.\n",
            "\n",
            "All the weights of MarianMTModel were initialized from the model checkpoint at opus-mt-uk-en-finetuned-sr-to-en/checkpoint-1000.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Turkey's Prime Minister at Anterrorist Zone\"]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "en_sr_test[\"translation\"][:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcR-a0mTDiA6",
        "outputId": "360df62a-84b2-4272-a6bb-531cd96bbae3"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'en': 'Turkey Preparing Amendments to Anti-Terror Law',\n",
              "  'sr': 'Turska priprema amandmane na antiteroristički zakon'},\n",
              " {'en': \"Turkey will submit amendments to its anti-terrorism law to parliament this autumn, the country's justice minister said this week.\",\n",
              "  'sr': 'Turska vlada će ove jeseni podneti parlamentu amandmane na antiteroristički zakon zemlje, saopštio je ove nedelje turski ministar pravosuđa.'},\n",
              " {'en': \"The move is one of the measures Turkey plans following a recent surge in incidents by terrorists affiliated with the banned Kurdistan Workers' Party.\",\n",
              "  'sr': 'Ovaj korak jedna je od mera koje Turska planira da sprovede nakon nedavnog porasta napada koje su izveli teroristi povezani sa zabranjenom Kurdistanskom radničkom partijom.'},\n",
              " {'en': '(The New York Times, Zaman, Xinhua, Journal of Turkish Weekly - 22/07/05; AFP, Reuters, AP, Turkish Press, UPI, Journal of Turkish Weekly - 21/07/05)',\n",
              "  'sr': '(Njujork Tajms, Zaman, Sinhua, Turski nedeljni žurnal - 22/07/05; AFP, Rojters, AP, Turska štampa, UPI, Turski nedeljni žurnal - 21/07/05)'},\n",
              " {'en': \"The new measures will not curb the expanded individual freedoms and human rights introduced over the past several years as part of Turkey's efforts to meet the democracy norms of the EU, said Justice Minister Cemil Cicek. [AFP]\",\n",
              "  'sr': 'Novim merama neće se ograničiti veće individualne slobode i ljudska prava uvedeni u poslednjih nekoliko godina u okviru napora Turske da ostvari demokratske norme EU, izjavio je ministar pravde Čemil Čiček. [AFP]'}]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# /content/opus-mt-uk-en-finetuned-sr-to-en\n",
        "!zip -r opus-mt-uk-en-finetuned-sr-to-en.zip opus-mt-uk-en-finetuned-sr-to-en/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5Mmm_coDh3l",
        "outputId": "456fe45d-af8a-4f41-f75d-87819a4f34c9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/ (stored 0%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/checkpoint-12000/ (stored 0%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/checkpoint-12000/tokenizer_config.json (deflated 40%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/checkpoint-12000/vocab.json (deflated 78%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/checkpoint-12000/pytorch_model.bin (deflated 7%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/checkpoint-12000/training_args.bin (deflated 49%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/checkpoint-12000/optimizer.pt (deflated 8%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/checkpoint-12000/config.json (deflated 60%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/checkpoint-12000/trainer_state.json (deflated 81%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/checkpoint-12000/special_tokens_map.json (deflated 34%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/checkpoint-12000/target.spm (deflated 51%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/checkpoint-12000/source.spm (deflated 57%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/checkpoint-12000/rng_state.pth (deflated 27%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/checkpoint-12000/scheduler.pt (deflated 49%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/runs/ (stored 0%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/runs/Jan26_21-35-26_d3e417588e2b/ (stored 0%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/runs/Jan26_21-35-26_d3e417588e2b/1643233087.3317487/ (stored 0%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/runs/Jan26_21-35-26_d3e417588e2b/1643233087.3317487/events.out.tfevents.1643233087.d3e417588e2b.1109.1 (deflated 62%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/runs/Jan26_21-35-26_d3e417588e2b/events.out.tfevents.1643233087.d3e417588e2b.1109.0 (deflated 63%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/runs/Jan26_21-00-26_d3e417588e2b/ (stored 0%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/runs/Jan26_21-00-26_d3e417588e2b/events.out.tfevents.1643230851.d3e417588e2b.387.0 (deflated 58%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/runs/Jan26_21-00-26_d3e417588e2b/1643230851.1944232/ (stored 0%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/runs/Jan26_21-00-26_d3e417588e2b/1643230851.1944232/events.out.tfevents.1643230851.d3e417588e2b.387.1 (deflated 62%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/checkpoint-11500/ (stored 0%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/checkpoint-11500/tokenizer_config.json (deflated 40%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/checkpoint-11500/vocab.json (deflated 78%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/checkpoint-11500/pytorch_model.bin (deflated 7%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/checkpoint-11500/training_args.bin (deflated 49%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/checkpoint-11500/optimizer.pt (deflated 8%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/checkpoint-11500/config.json (deflated 60%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/checkpoint-11500/trainer_state.json (deflated 81%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/checkpoint-11500/special_tokens_map.json (deflated 34%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/checkpoint-11500/target.spm (deflated 51%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/checkpoint-11500/source.spm (deflated 57%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/checkpoint-11500/rng_state.pth (deflated 27%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/checkpoint-11500/scheduler.pt (deflated 49%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/checkpoint-12500/ (stored 0%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/checkpoint-12500/tokenizer_config.json (deflated 40%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/checkpoint-12500/vocab.json (deflated 78%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/checkpoint-12500/pytorch_model.bin (deflated 7%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/checkpoint-12500/training_args.bin (deflated 49%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/checkpoint-12500/optimizer.pt (deflated 8%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/checkpoint-12500/config.json (deflated 60%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/checkpoint-12500/trainer_state.json (deflated 81%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/checkpoint-12500/special_tokens_map.json (deflated 34%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/checkpoint-12500/target.spm (deflated 51%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/checkpoint-12500/source.spm (deflated 57%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/checkpoint-12500/rng_state.pth (deflated 27%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/checkpoint-12500/scheduler.pt (deflated 50%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r opus-mt-uk-en-finetuned-sr-to-en_checkpoint-12500.zip opus-mt-uk-en-finetuned-sr-to-en/checkpoint-12500/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mfcbajyl3Bjj",
        "outputId": "e4e052cf-ae60-410a-f11f-109eb7c10d9d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/checkpoint-12500/ (stored 0%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/checkpoint-12500/tokenizer_config.json (deflated 40%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/checkpoint-12500/vocab.json (deflated 78%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/checkpoint-12500/pytorch_model.bin (deflated 7%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/checkpoint-12500/training_args.bin (deflated 49%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/checkpoint-12500/optimizer.pt (deflated 8%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/checkpoint-12500/config.json (deflated 60%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/checkpoint-12500/trainer_state.json (deflated 81%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/checkpoint-12500/special_tokens_map.json (deflated 34%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/checkpoint-12500/target.spm (deflated 51%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/checkpoint-12500/source.spm (deflated 57%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/checkpoint-12500/rng_state.pth (deflated 27%)\n",
            "  adding: opus-mt-uk-en-finetuned-sr-to-en/checkpoint-12500/scheduler.pt (deflated 50%)\n"
          ]
        }
      ]
    }
  ]
}